{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import create_template_model as CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports =\"\"\"\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from fbprophet import Prophet\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Class Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"PROPHET\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param = \"param\"\n",
    "\n",
    "input_params = f\"\"\"\n",
    "    self.parameters_list = kwargs.get('parameters_list',None)\n",
    "\"\"\"\n",
    "\n",
    "init_function = f\"\"\"\n",
    "def __init__(self,**kwargs):\n",
    "\n",
    "    #input parameters\n",
    "\n",
    "    self.train,self.test = kwargs.get('train'),kwargs.get('test')       \n",
    "    self.random_state = kwargs.get('random_state',1)\n",
    "    self.target_dates = kwargs.get('target_dates')\n",
    "    self.target_value = kwargs.get('target_value')\n",
    "    self.target_items = kwargs.get('target_items')\n",
    "    {input_params}\n",
    "    self.n_periods = kwargs.get('n_periods',3)\n",
    "\n",
    "    #output values\n",
    "    self.fitted_values = pd.DataFrame()\n",
    "    self.test_prediction = pd.DataFrame()\n",
    "    self.unseen_prediction = pd.DataFrame()        \n",
    "    self.apes = []\n",
    "    self.run_model()\n",
    "    del self.train,self.test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit method specific to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_method = f\"\"\"prophet_basic.fit(train_dataset)\n",
    "\"\"\"\n",
    "\n",
    "fit_function = f\"\"\"\n",
    "def fit(self,data,exog_data,param):\n",
    "        \n",
    "    ###########\n",
    "    #  Fit funtion will fit your train data and return model\n",
    "    ###########\n",
    "    return {fit_method}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_script = None\n",
    "predict_method = \"prophet_basic.predict(future)\"\n",
    "predict_function =f\"\"\"\n",
    "def predict(self,model,exog_data,start,n_periods):\n",
    "    return {predict_method} \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data = f\"model.fittedvalues[param[6]+param[1]:]\"\n",
    "fitted_function =f\"\"\"\n",
    "def fitted_data(self,model,param=None):\n",
    "    return {fitted_data} \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_functions = \"\"\"\n",
    "def split_train_test(self,subset_df):\n",
    "    return subset_df[:-3],subset_df[-3:]\n",
    "\n",
    "def mean_absolute_percentage_error(self,y_true,y_pred):\n",
    "    return np.mean(np.abs(np.subtract(y_true,y_pred)/y_true))*100  \n",
    "\n",
    "def calculate_apes(self):\n",
    "    for i,j in zip(self.test[self.target_value].values.flatten(),self.test_prediction.values.flatten()):            \n",
    "        self.apes.append(self.mean_absolute_percentage_error(i,j))\n",
    "\n",
    "def median_absolute_percentage_error_daily(self,y_true,y_pred):\n",
    "    y_true=pd.Series(y_true)\n",
    "    y_pred=pd.Series(y_pred)\n",
    "    true_pred = pd.DataFrame(zip(y_true,y_pred),columns=['y_true','y_pred'])\n",
    "    true_pred.drop(true_pred[true_pred['y_pred'] == 0].index, axis=0, inplace=True)\n",
    "    true_pred.drop(true_pred[true_pred['y_true'] == 0].index, axis=0, inplace=True)\n",
    "    return np.median(np.abs(np.subtract(true_pred.y_true,true_pred.y_pred)/true_pred.y_true))*100\n",
    "    \n",
    "def optimize_prophet(self,parameters_list,train_dataset,val_dataset,steps):  \n",
    "    results=[]\n",
    "    best_adj_mape=float('inf')\n",
    "    for i in tqdm(parameters_list):\n",
    "        forecast=pd.DataFrame()\n",
    "        future=pd.DataFrame()\n",
    "        \n",
    "        prophet_basic = Prophet(growth='linear',daily_seasonality=False,weekly_seasonality=True,yearly_seasonality=True,holidays_prior_scale=10,n_changepoints=i[0],changepoint_prior_scale=i[1])\n",
    "#        prophet_basic = Prophet(growth='linear',daily_seasonality=False,weekly_seasonality=True,yearly_seasonality=True,n_changepoints=20,changepoint_prior_scale=0.3)\n",
    "        prophet_basic.add_regressor('is_extended')\n",
    "        prophet_basic.add_regressor('Is_Month_End')\n",
    "        prophet_basic.add_regressor('LastButOneDay')\n",
    "        prophet_basic.add_regressor('LastSecDay')\n",
    "#        prophet_basic.add_regressor('6th_Day')\n",
    "        prophet_basic.add_regressor('13th_Day')\n",
    "#        prophet_basic.add_regressor('20th_Day')\n",
    "#        prophet_basic.add_regressor('27th_Day')\n",
    "        prophet_basic.add_regressor('31st_Day')\n",
    "        prophet_basic.add_country_holidays(country_name='US')\n",
    "#        prophet_basic.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "        prophet_basic.fit(train_dataset)\n",
    "        \n",
    "        future= prophet_basic.make_future_dataframe(periods=len(val_dataset))\n",
    "        x=train_dataset.append(val_dataset)\n",
    "        future['is_extended'] =pd.Series(x['is_extended'].values)\n",
    "        future['Is_Month_End'] =pd.Series(x['Is_Month_End'].values)\n",
    "        future['LastButOneDay'] =pd.Series(x['LastButOneDay'].values)\n",
    "        future['LastSecDay'] =pd.Series(x['LastSecDay'].values)\n",
    "#        future['6th_Day'] =pd.Series(x['6th_Day'].values)\n",
    "        future['13th_Day'] =pd.Series(x['13th_Day'].values)\n",
    "#        future['20th_Day'] =pd.Series(x['20th_Day'].values)\n",
    "#        future['27th_Day'] =pd.Series(x['27th_Day'].values)\n",
    "        future['31st_Day'] =pd.Series(x['31st_Day'].values)\n",
    "        forecast=prophet_basic.predict(future)\n",
    "        \n",
    "        y_true=np.array(list(train_dataset['y']))\n",
    "        y_pred=np.array(list(forecast.yhat[:-steps]))\n",
    "        val_predicted=np.array(list(forecast.yhat[-steps:]))\n",
    "        train_mape=round((median_absolute_percentage_error_daily(y_true[-365:],y_pred[-365:])),2)\n",
    "        val_mape=round((median_absolute_percentage_error_daily(val_dataset[\"y\"],val_predicted)),2)\n",
    "        adj_mape = train_mape*len(y_true)/(len(y_true)+len(val_dataset))+val_mape*len(val_dataset)/(len(y_true)+len(val_dataset))\n",
    "        \n",
    "        if adj_mape <= best_adj_mape:\n",
    "            best_adj_mape=adj_mape\n",
    "            best_model = prophet_basic\n",
    "            \n",
    "        results.append([i,train_mape,val_mape,adj_mape])\n",
    "        \n",
    "    result_table=pd.DataFrame(results,columns=['parameters','train_mape','val_mape','adj_mape'])\n",
    "    result_table=result_table.sort_values(by='adj_mape',ascending=True).reset_index(drop=True)\n",
    "    return result_table, best_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Models and storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_script = f\"\"\"\n",
    "def run_model(self):\n",
    "#    train_set,val_set,test_set,be_name=train[[\"total_charge\",\"is_extended\",\"Is_Month_End\",\"LastButOneDay\",\"LastSecDay\"]],val[[\"total_charge\",\"is_extended\",\"Is_Month_End\",\"LastButOneDay\",\"LastSecDay\"]],test[[\"total_charge\",\"is_extended\",\"Is_Month_End\",\"LastButOneDay\",\"LastSecDay\"]],be_name\n",
    "    train_dataset= pd.DataFrame()\n",
    "    val_dataset= pd.DataFrame()\n",
    "    train_set=train_set.reset_index()\n",
    "    val_set=val_set.reset_index()\n",
    "    train_dataset['ds'] = train_set[\"posted_date\"]\n",
    "    train_dataset['y']=train_set[\"total_charge\"]\n",
    "    train_dataset['is_extended']=train_set[\"is_extended\"]\n",
    "    train_dataset['Is_Month_End']=train_set[\"Is_Month_End\"]\n",
    "    train_dataset['LastButOneDay']=train_set[\"LastButOneDay\"]\n",
    "    train_dataset['LastSecDay']=train_set[\"LastSecDay\"]\n",
    "#    train_dataset['6th_Day']=train_set[\"6th_Day\"]\n",
    "    train_dataset['13th_Day']=train_set[\"13th_Day\"]\n",
    "#    train_dataset['20th_Day']=train_set[\"20th_Day\"]\n",
    "#    train_dataset['27th_Day']=train_set[\"27th_Day\"]\n",
    "    train_dataset['31st_Day']=train_set[\"31st_Day\"]\n",
    "    val_dataset['ds'] = val_set[\"posted_date\"]\n",
    "    val_dataset['y']=val_set[\"total_charge\"]\n",
    "    val_dataset['is_extended']=val_set[\"is_extended\"]\n",
    "    val_dataset['Is_Month_End']=val_set[\"Is_Month_End\"]\n",
    "    val_dataset['LastButOneDay']=val_set[\"LastButOneDay\"]\n",
    "    val_dataset['LastSecDay']=val_set[\"LastSecDay\"]\n",
    "#    val_dataset['6th_Day']=val_set[\"6th_Day\"]\n",
    "    val_dataset['13th_Day']=val_set[\"13th_Day\"]\n",
    "#    val_dataset['20th_Day']=val_set[\"20th_Day\"]\n",
    "#    val_dataset['27th_Day']=val_set[\"27th_Day\"]\n",
    "    val_dataset['31st_Day']=val_set[\"31st_Day\"]\n",
    "    steps = len(val_set)\n",
    "      \n",
    "    cp=(.001,.005,0.01,0.05,0.1,0.3)\n",
    "    ncp=(30,40)\n",
    "    \n",
    "    parameters=product(ncp,cp)\n",
    "    parameters_list=list(parameters)\n",
    "    result_table, best_model = optimize_prophet(parameters_list,train_dataset,val_dataset,steps)\n",
    "    future2= best_model.make_future_dataframe(periods=steps)\n",
    "    x=train_dataset.append(val_dataset)\n",
    "    future2['is_extended'] =pd.Series(x['is_extended'].values)\n",
    "    future2['Is_Month_End'] =pd.Series(x['Is_Month_End'].values)\n",
    "    future2['LastButOneDay'] =pd.Series(x['LastButOneDay'].values)\n",
    "    future2['LastSecDay'] =pd.Series(x['LastSecDay'].values)\n",
    "#    future2['6th_Day'] =pd.Series(x['6th_Day'].values)\n",
    "    future2['13th_Day'] =pd.Series(x['13th_Day'].values)\n",
    "#    future2['20th_Day'] =pd.Series(x['20th_Day'].values)\n",
    "#    future2['27th_Day'] =pd.Series(x['27th_Day'].values)\n",
    "    future2['31st_Day'] =pd.Series(x['31st_Day'].values)\n",
    "    forcast_val=best_model.predict(future2).yhat[-steps:]\n",
    "    \n",
    "    overall_train=pd.concat([train_set,val_set])\n",
    "    overall_train['ds'] = overall_train.posted_date\n",
    "    overall_train['y'] = overall_train[\"total_charge\"]\n",
    "    fitted_val_list=[]\n",
    "\n",
    "    c=1\n",
    "    for ncp,cp in result_table.parameters:\n",
    "        try:\n",
    "            if c > 3:\n",
    "                break\n",
    "            prophet_basic1 = Prophet(growth='linear',daily_seasonality=False,weekly_seasonality=True,yearly_seasonality=True,holidays_prior_scale=10,n_changepoints=ncp,changepoint_prior_scale=cp)\n",
    "#            prophet_basic1.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "            prophet_basic1.add_regressor('is_extended')\n",
    "            prophet_basic1.add_regressor('Is_Month_End')\n",
    "            prophet_basic1.add_regressor('LastButOneDay')\n",
    "            prophet_basic1.add_regressor('LastSecDay')\n",
    "#            prophet_basic1.add_regressor('6th_Day')\n",
    "            prophet_basic1.add_regressor('13th_Day')\n",
    "#            prophet_basic1.add_regressor('20th_Day')\n",
    "#            prophet_basic1.add_regressor('27th_Day')\n",
    "            prophet_basic1.add_regressor('31st_Day')\n",
    "            prophet_basic1.add_country_holidays(country_name='US')\n",
    "            prophet_basic1.fit(overall_train)\n",
    "            #if prophet_basic1.aic < res_aic_avg:\n",
    "            future1= prophet_basic1.make_future_dataframe(periods=len(test_set))\n",
    "            x=overall_train.append(test_set)\n",
    "            future1['is_extended'] =pd.Series(x['is_extended'].values)\n",
    "            future1['Is_Month_End'] =pd.Series(x['Is_Month_End'].values)\n",
    "            future1['LastButOneDay'] =pd.Series(x['LastButOneDay'].values)\n",
    "            future1['LastSecDay'] =pd.Series(x['LastSecDay'].values)\n",
    "#            future1['6th_Day'] =pd.Series(x['6th_Day'].values)\n",
    "            future1['13th_Day'] =pd.Series(x['13th_Day'].values)\n",
    "#            future1['20th_Day'] =pd.Series(x['20th_Day'].values)\n",
    "#            future1['27th_Day'] =pd.Series(x['27th_Day'].values)\n",
    "            future1['31st_Day'] =pd.Series(x['31st_Day'].values)\n",
    "            forecast=prophet_basic1.predict(future1).yhat[-(len(test_set)):]\n",
    "            c=c+1\n",
    "            get_list=[]\n",
    "            for i in range(len(forecast)):\n",
    "                get_list.append(forecast.iloc[i])\n",
    "            fitted_val_list.append(get_list)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    fitted_val=pd.DataFrame(fitted_val_list,columns=[x for x in range(1,len(test_set)+1)])\n",
    "\n",
    "    fitted_mean=[]\n",
    "    for i in range(1,len(test_set)+1):\n",
    "        fitted_mean.append(fitted_val[i].mean())\n",
    "        \n",
    "    test_set1=np.array(list(test_set[\"total_charge\"]))\n",
    "    test_results=round(median_absolute_percentage_error_daily(test_set1,fitted_mean),2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "template_dict = dict(imports=imports,class_name=class_name,init_function=init_function,\n",
    "                         fit_function=fit_function,fitted_function=fitted_function,predict_function=predict_function,\n",
    "                        additional_functions=additional_functions,run_script=run_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT.render_template(template_dict=template_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Import files\n",
      "\n",
      "\n",
      "from itertools import product\n",
      "from tqdm import tqdm\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "from fbprophet import Prophet\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "#Model class\n",
      "class PROPHET:\n",
      "\n",
      "  \n",
      "\n",
      "    def __init__(self,**kwargs):\n",
      "\n",
      "        #input parameters\n",
      "\n",
      "        self.train,self.test = kwargs.get('train'),kwargs.get('test')       \n",
      "        self.random_state = kwargs.get('random_state',1)\n",
      "        self.target_dates = kwargs.get('target_dates')\n",
      "        self.target_value = kwargs.get('target_value')\n",
      "        self.target_items = kwargs.get('target_items')\n",
      "        \n",
      "        self.parameters_list = kwargs.get('parameters_list',None)\n",
      "\n",
      "        self.n_periods = kwargs.get('n_periods',3)\n",
      "\n",
      "        #output values\n",
      "        self.fitted_values = pd.DataFrame()\n",
      "        self.test_prediction = pd.DataFrame()\n",
      "        self.unseen_prediction = pd.DataFrame()        \n",
      "        self.apes = []\n",
      "        self.run_model()\n",
      "        del self.train,self.test\n",
      "\n",
      "\n",
      "\n",
      "    def fit(self,data,exog_data,param):\n",
      "            \n",
      "        ###########\n",
      "        #  Fit funtion will fit your train data and return model\n",
      "        ###########\n",
      "        return prophet_basic.fit(train_dataset)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def fitted_data(self,model,param=None):\n",
      "        return model.fittedvalues[param[6]+param[1]:] \n",
      "\n",
      "\n",
      "\n",
      "    def predict(self,model,exog_data,start,n_periods):\n",
      "        return prophet_basic.predict(future) \n",
      "\n",
      "\n",
      "\n",
      "    def split_train_test(self,subset_df):\n",
      "        return subset_df[:-3],subset_df[-3:]\n",
      "\n",
      "    def mean_absolute_percentage_error(self,y_true,y_pred):\n",
      "        return np.mean(np.abs(np.subtract(y_true,y_pred)/y_true))*100  \n",
      "\n",
      "    def calculate_apes(self):\n",
      "        for i,j in zip(self.test[self.target_value].values.flatten(),self.test_prediction.values.flatten()):            \n",
      "            self.apes.append(self.mean_absolute_percentage_error(i,j))\n",
      "\n",
      "    def median_absolute_percentage_error_daily(self,y_true,y_pred):\n",
      "        y_true=pd.Series(y_true)\n",
      "        y_pred=pd.Series(y_pred)\n",
      "        true_pred = pd.DataFrame(zip(y_true,y_pred),columns=['y_true','y_pred'])\n",
      "        true_pred.drop(true_pred[true_pred['y_pred'] == 0].index, axis=0, inplace=True)\n",
      "        true_pred.drop(true_pred[true_pred['y_true'] == 0].index, axis=0, inplace=True)\n",
      "        return np.median(np.abs(np.subtract(true_pred.y_true,true_pred.y_pred)/true_pred.y_true))*100\n",
      "        \n",
      "    def optimize_prophet(self,parameters_list,train_dataset,val_dataset,steps):  \n",
      "        results=[]\n",
      "        best_adj_mape=float('inf')\n",
      "        for i in tqdm(parameters_list):\n",
      "            forecast=pd.DataFrame()\n",
      "            future=pd.DataFrame()\n",
      "            \n",
      "            prophet_basic = Prophet(growth='linear',daily_seasonality=False,weekly_seasonality=True,yearly_seasonality=True,holidays_prior_scale=10,n_changepoints=i[0],changepoint_prior_scale=i[1])\n",
      "    #        prophet_basic = Prophet(growth='linear',daily_seasonality=False,weekly_seasonality=True,yearly_seasonality=True,n_changepoints=20,changepoint_prior_scale=0.3)\n",
      "            prophet_basic.add_regressor('is_extended')\n",
      "            prophet_basic.add_regressor('Is_Month_End')\n",
      "            prophet_basic.add_regressor('LastButOneDay')\n",
      "            prophet_basic.add_regressor('LastSecDay')\n",
      "    #        prophet_basic.add_regressor('6th_Day')\n",
      "            prophet_basic.add_regressor('13th_Day')\n",
      "    #        prophet_basic.add_regressor('20th_Day')\n",
      "    #        prophet_basic.add_regressor('27th_Day')\n",
      "            prophet_basic.add_regressor('31st_Day')\n",
      "            prophet_basic.add_country_holidays(country_name='US')\n",
      "    #        prophet_basic.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
      "            prophet_basic.fit(train_dataset)\n",
      "            \n",
      "            future= prophet_basic.make_future_dataframe(periods=len(val_dataset))\n",
      "            x=train_dataset.append(val_dataset)\n",
      "            future['is_extended'] =pd.Series(x['is_extended'].values)\n",
      "            future['Is_Month_End'] =pd.Series(x['Is_Month_End'].values)\n",
      "            future['LastButOneDay'] =pd.Series(x['LastButOneDay'].values)\n",
      "            future['LastSecDay'] =pd.Series(x['LastSecDay'].values)\n",
      "    #        future['6th_Day'] =pd.Series(x['6th_Day'].values)\n",
      "            future['13th_Day'] =pd.Series(x['13th_Day'].values)\n",
      "    #        future['20th_Day'] =pd.Series(x['20th_Day'].values)\n",
      "    #        future['27th_Day'] =pd.Series(x['27th_Day'].values)\n",
      "            future['31st_Day'] =pd.Series(x['31st_Day'].values)\n",
      "            forecast=prophet_basic.predict(future)\n",
      "            \n",
      "            y_true=np.array(list(train_dataset['y']))\n",
      "            y_pred=np.array(list(forecast.yhat[:-steps]))\n",
      "            val_predicted=np.array(list(forecast.yhat[-steps:]))\n",
      "            train_mape=round((median_absolute_percentage_error_daily(y_true[-365:],y_pred[-365:])),2)\n",
      "            val_mape=round((median_absolute_percentage_error_daily(val_dataset[\"y\"],val_predicted)),2)\n",
      "            adj_mape = train_mape*len(y_true)/(len(y_true)+len(val_dataset))+val_mape*len(val_dataset)/(len(y_true)+len(val_dataset))\n",
      "            \n",
      "            if adj_mape <= best_adj_mape:\n",
      "                best_adj_mape=adj_mape\n",
      "                best_model = prophet_basic\n",
      "                \n",
      "            results.append([i,train_mape,val_mape,adj_mape])\n",
      "            \n",
      "        result_table=pd.DataFrame(results,columns=['parameters','train_mape','val_mape','adj_mape'])\n",
      "        result_table=result_table.sort_values(by='adj_mape',ascending=True).reset_index(drop=True)\n",
      "        return result_table, best_model\n",
      "      \n",
      "\n",
      "\n",
      "    def run_model(self):\n",
      "    #    train_set,val_set,test_set,be_name=train[[\"total_charge\",\"is_extended\",\"Is_Month_End\",\"LastButOneDay\",\"LastSecDay\"]],val[[\"total_charge\",\"is_extended\",\"Is_Month_End\",\"LastButOneDay\",\"LastSecDay\"]],test[[\"total_charge\",\"is_extended\",\"Is_Month_End\",\"LastButOneDay\",\"LastSecDay\"]],be_name\n",
      "        train_dataset= pd.DataFrame()\n",
      "        val_dataset= pd.DataFrame()\n",
      "        train_set=train_set.reset_index()\n",
      "        val_set=val_set.reset_index()\n",
      "        train_dataset['ds'] = train_set[\"posted_date\"]\n",
      "        train_dataset['y']=train_set[\"total_charge\"]\n",
      "        train_dataset['is_extended']=train_set[\"is_extended\"]\n",
      "        train_dataset['Is_Month_End']=train_set[\"Is_Month_End\"]\n",
      "        train_dataset['LastButOneDay']=train_set[\"LastButOneDay\"]\n",
      "        train_dataset['LastSecDay']=train_set[\"LastSecDay\"]\n",
      "    #    train_dataset['6th_Day']=train_set[\"6th_Day\"]\n",
      "        train_dataset['13th_Day']=train_set[\"13th_Day\"]\n",
      "    #    train_dataset['20th_Day']=train_set[\"20th_Day\"]\n",
      "    #    train_dataset['27th_Day']=train_set[\"27th_Day\"]\n",
      "        train_dataset['31st_Day']=train_set[\"31st_Day\"]\n",
      "        val_dataset['ds'] = val_set[\"posted_date\"]\n",
      "        val_dataset['y']=val_set[\"total_charge\"]\n",
      "        val_dataset['is_extended']=val_set[\"is_extended\"]\n",
      "        val_dataset['Is_Month_End']=val_set[\"Is_Month_End\"]\n",
      "        val_dataset['LastButOneDay']=val_set[\"LastButOneDay\"]\n",
      "        val_dataset['LastSecDay']=val_set[\"LastSecDay\"]\n",
      "    #    val_dataset['6th_Day']=val_set[\"6th_Day\"]\n",
      "        val_dataset['13th_Day']=val_set[\"13th_Day\"]\n",
      "    #    val_dataset['20th_Day']=val_set[\"20th_Day\"]\n",
      "    #    val_dataset['27th_Day']=val_set[\"27th_Day\"]\n",
      "        val_dataset['31st_Day']=val_set[\"31st_Day\"]\n",
      "        steps = len(val_set)\n",
      "          \n",
      "        cp=(.001,.005,0.01,0.05,0.1,0.3)\n",
      "        ncp=(30,40)\n",
      "        \n",
      "        parameters=product(ncp,cp)\n",
      "        parameters_list=list(parameters)\n",
      "        result_table, best_model = optimize_prophet(parameters_list,train_dataset,val_dataset,steps)\n",
      "        future2= best_model.make_future_dataframe(periods=steps)\n",
      "        x=train_dataset.append(val_dataset)\n",
      "        future2['is_extended'] =pd.Series(x['is_extended'].values)\n",
      "        future2['Is_Month_End'] =pd.Series(x['Is_Month_End'].values)\n",
      "        future2['LastButOneDay'] =pd.Series(x['LastButOneDay'].values)\n",
      "        future2['LastSecDay'] =pd.Series(x['LastSecDay'].values)\n",
      "    #    future2['6th_Day'] =pd.Series(x['6th_Day'].values)\n",
      "        future2['13th_Day'] =pd.Series(x['13th_Day'].values)\n",
      "    #    future2['20th_Day'] =pd.Series(x['20th_Day'].values)\n",
      "    #    future2['27th_Day'] =pd.Series(x['27th_Day'].values)\n",
      "        future2['31st_Day'] =pd.Series(x['31st_Day'].values)\n",
      "        forcast_val=best_model.predict(future2).yhat[-steps:]\n",
      "        \n",
      "        overall_train=pd.concat([train_set,val_set])\n",
      "        overall_train['ds'] = overall_train.posted_date\n",
      "        overall_train['y'] = overall_train[\"total_charge\"]\n",
      "        fitted_val_list=[]\n",
      "\n",
      "        c=1\n",
      "        for ncp,cp in result_table.parameters:\n",
      "            try:\n",
      "                if c > 3:\n",
      "                    break\n",
      "                prophet_basic1 = Prophet(growth='linear',daily_seasonality=False,weekly_seasonality=True,yearly_seasonality=True,holidays_prior_scale=10,n_changepoints=ncp,changepoint_prior_scale=cp)\n",
      "    #            prophet_basic1.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
      "                prophet_basic1.add_regressor('is_extended')\n",
      "                prophet_basic1.add_regressor('Is_Month_End')\n",
      "                prophet_basic1.add_regressor('LastButOneDay')\n",
      "                prophet_basic1.add_regressor('LastSecDay')\n",
      "    #            prophet_basic1.add_regressor('6th_Day')\n",
      "                prophet_basic1.add_regressor('13th_Day')\n",
      "    #            prophet_basic1.add_regressor('20th_Day')\n",
      "    #            prophet_basic1.add_regressor('27th_Day')\n",
      "                prophet_basic1.add_regressor('31st_Day')\n",
      "                prophet_basic1.add_country_holidays(country_name='US')\n",
      "                prophet_basic1.fit(overall_train)\n",
      "                #if prophet_basic1.aic < res_aic_avg:\n",
      "                future1= prophet_basic1.make_future_dataframe(periods=len(test_set))\n",
      "                x=overall_train.append(test_set)\n",
      "                future1['is_extended'] =pd.Series(x['is_extended'].values)\n",
      "                future1['Is_Month_End'] =pd.Series(x['Is_Month_End'].values)\n",
      "                future1['LastButOneDay'] =pd.Series(x['LastButOneDay'].values)\n",
      "                future1['LastSecDay'] =pd.Series(x['LastSecDay'].values)\n",
      "    #            future1['6th_Day'] =pd.Series(x['6th_Day'].values)\n",
      "                future1['13th_Day'] =pd.Series(x['13th_Day'].values)\n",
      "    #            future1['20th_Day'] =pd.Series(x['20th_Day'].values)\n",
      "    #            future1['27th_Day'] =pd.Series(x['27th_Day'].values)\n",
      "                future1['31st_Day'] =pd.Series(x['31st_Day'].values)\n",
      "                forecast=prophet_basic1.predict(future1).yhat[-(len(test_set)):]\n",
      "                c=c+1\n",
      "                get_list=[]\n",
      "                for i in range(len(forecast)):\n",
      "                    get_list.append(forecast.iloc[i])\n",
      "                fitted_val_list.append(get_list)\n",
      "\n",
      "            except:\n",
      "                continue\n",
      "            \n",
      "        fitted_val=pd.DataFrame(fitted_val_list,columns=[x for x in range(1,len(test_set)+1)])\n",
      "\n",
      "        fitted_mean=[]\n",
      "        for i in range(1,len(test_set)+1):\n",
      "            fitted_mean.append(fitted_val[i].mean())\n",
      "            \n",
      "        test_set1=np.array(list(test_set[\"total_charge\"]))\n",
      "        test_results=round(median_absolute_percentage_error_daily(test_set1,fitted_mean),2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CT.get_ouput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPHET'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.TBATS_MODEL import TBATS_CLASS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('model_params.json') as f:\n",
    "  config = json.load(f)\n",
    "\n",
    "with open('data-config.json') as f1:\n",
    "  data_config = json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['not_include_be_list', 'overall_be', 'aggregate_choice', 'target_file', 'target_dates', 'target_value', 'target_item', 'other_target_value', 'data_length', 'n_periods', 'minor_holidays', 'major_holidays', 'processed_data_path', 'wf_res_path', 'best_model_path'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()\n",
    "data_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_charge</th>\n",
       "      <th>footfall</th>\n",
       "      <th>minor_holiday</th>\n",
       "      <th>major_holiday</th>\n",
       "      <th>observed_holiday</th>\n",
       "      <th>is_extended</th>\n",
       "      <th>count_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>8.659224e+08</td>\n",
       "      <td>261407.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1.020063e+09</td>\n",
       "      <td>298243.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1.034977e+09</td>\n",
       "      <td>307918.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1.017733e+09</td>\n",
       "      <td>286794.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>9.889783e+08</td>\n",
       "      <td>293472.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total_charge  footfall  minor_holiday  major_holiday  \\\n",
       "posted_date                                                         \n",
       "2015-05-31   8.659224e+08  261407.0              0              0   \n",
       "2015-06-30   1.020063e+09  298243.0              0              0   \n",
       "2015-07-31   1.034977e+09  307918.0              0              0   \n",
       "2015-08-31   1.017733e+09  286794.0              0              0   \n",
       "2015-09-30   9.889783e+08  293472.0              0              0   \n",
       "\n",
       "             observed_holiday  is_extended  count_weekend  \n",
       "posted_date                                                \n",
       "2015-05-31                  0            0              1  \n",
       "2015-06-30                  0            0              8  \n",
       "2015-07-31                  0            0              8  \n",
       "2015-08-31                  0            0             10  \n",
       "2015-09-30                  0            0              8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "target_dates = 'posted_date'\n",
    "target_values = 'total_charge'\n",
    "target_items = 'billing_entity'\n",
    "#transformed_data_path = \n",
    "#r'C:\\Users\\CK073783\\OneDrive - Cerner Corporation\\Desktop\\Projects\\Revenue Forecasting\\Versions\\version 2\\data\\processed_data\\All Adventist W\\\\'\n",
    "\n",
    "#data_files = os.listdir(transformed_data_path)\n",
    "#model_output_path = r'C:\\Users\\CK073783\\OneDrive - Cerner Corporation\\Desktop\\Projects\\Revenue Forecasting\\Versions\\version 2\\data\\model_output\\\\'\n",
    "\n",
    "def filter_data(ti):\n",
    "    subset_df = preprocessed_data[preprocessed_data[target_items]==ti].reset_index()\n",
    "    subset_df[target_dates] = pd.to_datetime(subset_df[target_dates])\n",
    "    subset_df = subset_df.sort_values(target_dates)#.reset_index()\n",
    "    subset_df=subset_df.drop([target_items],axis=1)\n",
    "    subset_df.set_index(target_dates,inplace=True)\n",
    "#    print(\"subset_df\",subset_df.head(5))\n",
    "    return subset_df\n",
    "\n",
    "#filename = data_files[0]\n",
    "filehandler = open(data_config[\"processed_data_path\"], 'rb') \n",
    "data_object = pickle.load(filehandler)\n",
    "data_date = data_object.summary_df.end_date.max().month_name() +'-'+str(data_object.summary_df.end_date.max().year)\n",
    "\n",
    "preprocessed_data  = data_object.transform_data#[data_object.transform_data[target_items].isin(filter_data(data_object.summary_df))]\n",
    "BE = 'All Adventist W'\n",
    "subset_df=filter_data(BE)\n",
    "#subset_df = filtered_data[filtered_data[target_items]==BE].reset_index(drop=True)\n",
    "#subset_df[target_dates] = pd.to_datetime(subset_df[target_dates]).copy()\n",
    "#subset_df.set_index('posted_date',inplace=True)\n",
    "# models = Univariate(BE,data = subset_df[target_value],target_items= target_items,target_value=target_value,target_dates=target_dates)\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(True, True, True, True), (True, True, True, False), (True, True, False, True), (True, True, False, False), (True, False, True, True), (True, False, True, False), (True, False, False, True), (True, False, False, False), (False, True, True, True), (False, True, True, False), (False, True, False, True), (False, True, False, False), (False, False, True, True), (False, False, True, False), (False, False, False, True), (False, False, False, False)]\n",
      "dict_keys(['not_include_be_list', 'overall_be', 'aggregate_choice', 'target_file', 'target_dates', 'target_value', 'target_item', 'other_target_value', 'data_length', 'n_periods', 'minor_holidays', 'major_holidays', 'processed_data_path', 'wf_res_path', 'best_model_path', 'parameters_list', 'train', 'test', 'ti'])\n"
     ]
    }
   ],
   "source": [
    "# from itertools import product\n",
    "# def split_train_test(subset_df):\n",
    "#         return subset_df[:-3],subset_df[-3:]\n",
    "# train,test = split_train_test(subset_df)\n",
    "#p=range(0,2)\n",
    "#d=range(0,1)\n",
    "#q=range(0,2)\n",
    "#P=range(0,2)\n",
    "# D=range(0,1)\n",
    "# Q=range(0,2)\n",
    "# s=(3,6,12)\n",
    "\n",
    "# parameters=product(p,d,q,P,D,Q,s)\n",
    "# parameters_list=list(parameters)\n",
    "\n",
    "use_arma_errors=[True,False]\n",
    "use_box_cox=[True,False]\n",
    "use_trend=[True,False]\n",
    "use_damped_trend=[True,False]  \n",
    "\n",
    "parameters=product(use_arma_errors,use_box_cox,use_trend,use_damped_trend)\n",
    "parameters_list=list(parameters)\n",
    "print(parameters_list)\n",
    "def check(**kwargs):\n",
    "    print(kwargs.keys())\n",
    "data_config['parameters_list'] = parameters_list\n",
    "data_config['train'] = train\n",
    "data_config['test'] = test\n",
    "data_config['ti'] = BE\n",
    "check(**data_config)\n",
    "# obj = TBATS_CLASS(**data_config)\n",
    "#print(\"in model.py results\",df.mape_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.apes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.unseen_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'target_items',\n",
       " 'target_value',\n",
       " 'other_target_value',\n",
       " 'target_dates',\n",
       " 'n_periods',\n",
       " 'set_no',\n",
       " 'wf',\n",
       " 'parameters_list',\n",
       " 'train',\n",
       " 'test',\n",
       " 'ti']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['data', 'target_items', 'target_value', 'other_target_value', 'target_dates', 'n_periods', 'set_no', 'wf', 'parameters_list', 'train', 'test', 'ti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
